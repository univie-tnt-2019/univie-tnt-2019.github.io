---
layout: page
title: L07 Webscraping
subtitle: Getting to know `Wget`
---

# Goals:

Introduction into webscraping, or how one can efficiently collect lots of information from the Internet .


# Software:

* `wget` (<https://www.gnu.org/software/wget/>), a free software package for retrieving files using HTTP, HTTPS, FTP and FTPS the most widely-used Internet protocols. It is a non-interactive command line tool, so it may easily be called from scripts, cron jobs, terminals without X-Windows support, etc.

* **NB**: on installing `wget`, see Ian Milligan’s “Automated Downloading with Wget”, <https://programminghistorian.org/lessons/automated-downloading-with-wget>
	* Alternatively, for Windows: <https://builtvisible.com/download-your-website-with-wget/>
	* On Mac (and, possibly, Linux): `brew install wget`

# Class:

* practical examples of working with `wget`
* single link download
* batch download
	* web-page analysis
	* extraction of links with `regular expressions`
	* modification of links with `regular expressions`

# Sample commands

```
wget link
wget -i file_with_links.txt
wget -i links.txt -P ./folderYouWantToSaveTo/ -nc 
```

Where:

* `-P` is a folder parameter, which instructs `wget` where you want to store downloaded files (*optional*).
* `-nc` is a *no-clobber* parameter, which instructs `wget` to skips files, if they already exist (*optional*)

**NB:** there are many other parameters with which you can adjust `wget` to your needs.


# Examples for Downloading

## Practice 1: very easy

* [Article 01](https://univie-tnt-2018-summer.github.io/files/07/articles/1860-11-12_article_01.txt)
* [Article 02](https://univie-tnt-2018-summer.github.io/files/07/articles/1860-11-12_article_02.txt)
* [Article 03](https://univie-tnt-2018-summer.github.io/files/07/articles/1860-11-12_article_03.txt)
* [Article 04](https://univie-tnt-2018-summer.github.io/files/07/articles/1860-11-12_article_04.txt)
* [Article 05](https://univie-tnt-2018-summer.github.io/files/07/articles/1860-11-12_article_05.txt)
* [Article 06](https://univie-tnt-2018-summer.github.io/files/07/articles/1860-11-12_article_06.txt)
* [Article 07](https://univie-tnt-2018-summer.github.io/files/07/articles/1860-11-12_article_07.txt)
* [Article 08](https://univie-tnt-2018-summer.github.io/files/07/articles/1860-11-12_article_08.txt)
* [Article 09](https://univie-tnt-2018-summer.github.io/files/07/articles/1860-11-12_article_09.txt)
* [Article 10](https://univie-tnt-2018-summer.github.io/files/07/articles/1860-11-12_article_10.txt)
* [Article 11](https://univie-tnt-2018-summer.github.io/files/07/articles/1860-11-12_article_11.txt)
* [Article 12](https://univie-tnt-2018-summer.github.io/files/07/articles/1860-11-12_article_12.txt)
* [Article 13](https://univie-tnt-2018-summer.github.io/files/07/articles/1860-11-12_article_13.txt)
* [Article 14](https://univie-tnt-2018-summer.github.io/files/07/articles/1860-11-12_article_14.txt)
* [Article 15](https://univie-tnt-2018-summer.github.io/files/07/articles/1860-11-12_article_15.txt)

## Practice 2: easy-ish

* [Article 16](./files/07/articles/1860-11-12_article_16.txt)
* [Article 17](./files/07/articles/1860-11-12_article_17.txt)
* [Article 18](./files/07/articles/1860-11-12_article_18.txt)
* [Article 19](./files/07/articles/1860-11-12_article_19.txt)
* [Article 20](./files/07/articles/1860-11-12_article_20.txt)
* [Article 21](./files/07/articles/1860-11-12_article_21.txt)
* [Article 22](./files/07/articles/1860-11-12_article_22.txt)
* [Article 23](./files/07/articles/1860-11-12_article_23.txt)
* [Article 24](./files/07/articles/1860-11-12_article_24.txt)
* [Article 25](./files/07/articles/1860-11-12_article_25.txt)
* [Article 26](./files/07/articles/1860-11-12_article_26.txt)
* [Article 27](./files/07/articles/1860-11-12_article_27.txt)
* [Article 28](./files/07/articles/1860-11-12_article_28.txt)
* [Article 29](./files/07/articles/1860-11-12_article_29.txt)
* [Article 30](./files/07/articles/1860-11-12_article_30.txt)
* [Article 31](./files/07/articles/1860-11-12_article_31.txt)
* [Article 32](./files/07/articles/1860-11-12_article_32.txt)
* [Article 33](./files/07/articles/1860-11-12_article_33.txt)
* [Article 34](./files/07/articles/1860-11-12_article_34.txt)
* [Article 35](./files/07/articles/1860-11-12_article_35.txt)
* [Article 36](./files/07/articles/1860-11-12_article_36.txt)
* [Article 37](./files/07/articles/1860-11-12_article_37.txt)
* [Article 38](./files/07/articles/1860-11-12_article_38.txt)
* [Article 39](./files/07/articles/1860-11-12_article_39.txt)

## Practice 3 (aka *Homework*): a tiny-bit tricky

* download issues of “Richmond Times Dispatch” (Years 1860-1865, only!), which are available at: <http://www.perseus.tufts.edu/hopper/collection?collection=Perseus:collection:RichTimes>)

# Reference Materials:

* Milligan, Ian. 2012. “Automated Downloading with Wget.” Programming Historian, June. <https://programminghistorian.org/lessons/automated-downloading-with-wget>.
* Kurschinski, Kellen. 2013. “Applied Archival Downloading with Wget.” Programming Historian, September. <https://programminghistorian.org/lessons/applied-archival-downloading-with-wget>.
* Alternatively, this operation can be done with a Python script: Turkel, William J., and Adam Crymble. 2012. “Downloading Web Pages with Python.” Programming Historian, July. <https://programminghistorian.org/lessons/working-with-web-pages>.

# Homework:

1. Scraping the “Dispatch”: download issues of “Richmond Times Dispatch” (Years 1860-1865, only!), which are available at: <http://www.perseus.tufts.edu/hopper/collection?collection=Perseus:collection:RichTimes>)
2. Publish a step-by-step explanation of what you have done as a blogpost on your website.
3. Codecademy’s Learn Python, Unit 7-8.
4. Github: publish the confirmation screenshot as a post on your new site.
